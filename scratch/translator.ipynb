{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf47f195-66df-4daa-8e71-43aadc5c15a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8515a737-11c3-44b9-b8d7-57882b1e4fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6240bdb2-2207-4603-b5bd-9d1afcc27d1b",
   "metadata": {},
   "source": [
    "## get data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "29cc56a2-e384-4b45-88f8-0d13f23d9bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ger_train_path = \"/home/adam/play/translate_data/train.de\"\n",
    "eng_train_path = \"/home/adam/play/translate_data/train.en\"\n",
    "\n",
    "ger_train_raw = open(ger_train_path, \"r\").readlines()\n",
    "eng_train_raw = open(eng_train_path, \"r\").readlines()\n",
    "\n",
    "# just to help my poor laptop\n",
    "ger_train_raw = ger_train_raw[:10000]\n",
    "eng_train_raw = eng_train_raw[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "1b342e7e-bd9c-489d-9cf0-f675475d0cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(ger_train))\n",
    "print(len(eng_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e981672b-1d7a-4ca9-907a-55240ad8540f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### tokenize \n",
    "tokenizer = Tokenizer(BPE())\n",
    "\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"]) # do i need to account for the weird #AT things??\n",
    "tokenizer.train(files=[ger_train_path, eng_train_path,], trainer=trainer)\n",
    "tokenizer.enable_padding()\n",
    "# tokenizer.train_from_iterator(iter(ger_train + eng_train), trainer=trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "55d01b5a-9e04-4196-a256-71e7bd72ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ger_train = tokenizer.encode_batch(ger_train_raw)\n",
    "eng_train = tokenizer.encode_batch(eng_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e6ce4708-7281-4a8f-9cad-41582ff471e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ger_train = torch.tensor([t.ids for t in ger_train])\n",
    "eng_train = torch.tensor([t.ids for t in eng_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "76ac0bce-b8da-4852-b2b4-929d4c4bfad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 258])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ger_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781269b0-71c1-4034-8dc1-db1fd038c0b7",
   "metadata": {},
   "source": [
    "## define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "411dbe29-89cd-415a-8abc-a96b4322b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(src, targ, pad_token):\n",
    "    # NOTE: not fully confident in the unsqueeze - i think we get the extra-dimension so the masked_fill can broadcast it \n",
    "    # we want to broadcast for the padding mask because it's the same on both axes (unlike with the causal mask) \n",
    "    src_pad_mask = (src != pad_token).unsqueeze(1) # (B, 1, context_size)\n",
    "    targ_pad_mask = (targ != pad_token).unsqueeze(1)\n",
    "    full_mask = torch.ones((targ.shape[1], targ.shape[1])).type(torch.int)\n",
    "    causal_atten_mask = torch.tril(full_mask) # (context_size, context_size)\n",
    "\n",
    "    return src_pad_mask, targ_pad_mask & causal_atten_mask\n",
    "\n",
    "def calculate_loss(logits, labels, pad_idx):\n",
    "    B, T, V = logits.shape # (batch, context_size, vocab_size)\n",
    "    # cross entropy expects list of indices and logits requiring reshape\n",
    "    return F.cross_entropy(logits.reshape(B * T, V), labels.reshape(B * T), ignore_index=pad_idx)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads, n_embed, dropout):\n",
    "        super().__init__()\n",
    "        self.n_embed = n_embed\n",
    "        self.n_heads = n_heads\n",
    "        assert(n_embed % n_heads == 0) # check dims work\n",
    "        self.head_size = n_embed // n_heads\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.wk = nn.Linear(n_embed, n_embed, bias=False)\n",
    "        self.wq = nn.Linear(n_embed, n_embed, bias=False)\n",
    "        self.wv = nn.Linear(n_embed, n_embed, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.proj = nn.Linear(n_embed, n_embed)\n",
    "        self.attn_store = None\n",
    "\n",
    "    def forward(self, x, features, mask):\n",
    "        B, T, C = features.shape # (batch, context_size, n_embed)\n",
    "\n",
    "        # create k\n",
    "        # NOTE: make sure the maths works here\n",
    "        k = self.wk(features) # (B, context_size, n_embed) @ (n_embed, n_embed) ---> (B, context_size, n_embed)\n",
    "        # split per head\n",
    "        k = k.view(B, T, self.n_heads, self.head_size)  # (B, context_size, n_embed) --> (B, context_size, n_heads, head_size)\n",
    "        # switch context size and n_heads dim so we can batch matmul over B and n_heads\n",
    "        k = k.transpose(1,2) # (B, context_size, n_heads, head_size) --> (B, n_heads, context_size, head_size)\n",
    "        \n",
    "        # create q \n",
    "        q = self.wq(x)\n",
    "        q = q.view(q.shape[0], q.shape[1], self.n_heads, self.head_size) # q can be a different shape to k and v so need to use its own shape\n",
    "        q = q.transpose(1,2)\n",
    "\n",
    "        # create v \n",
    "        v = self.wv(features)\n",
    "        v = v.view(B, T, self.n_heads, self.head_size)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        attn = q @ k.transpose(-2, -1) # (B, n_heads, context_size, head_size) @ (B, n_heads, head_size, context_size) --> (B, n_heads, context_size, context_size)\n",
    "        attn = attn / (self.n_embed ** 0.5) # divide by squareroot of n_embed to decrease magnitude\n",
    "        \n",
    "        # if this is a masked attention layer (causal?) mask out all tokens before the cur pos, otherwise just mask out padding \n",
    "        attn = attn.masked_fill(mask.unsqueeze(1) == 0, float(\"-inf\")) # TODO: check that the dimensions here work\n",
    "        self.attn_store = attn\n",
    "        attn = self.dropout(F.softmax(attn, dim=-1))\n",
    "        \n",
    "        # generate the v matrix and use the attn matrix to pluck out relevant info on a per head basis\n",
    "        out = attn @ v # (B, n_heads, context_size, context_size) @ (B, n_heads, context_size, head_size) --> (B, n_heads, context_size, head_size)\n",
    "        # remove per-head dimension and use final linear projection\n",
    "        out = out.view(out.shape[0], -1, self.n_embed) # (B, n_heads, context_size, head_size) --> (B, context_size, n_embed)\n",
    "        return self.proj(out)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embed, dropout):\n",
    "        super().__init__()\n",
    "        self.ffw = nn.Sequential(\n",
    "            nn.Linear(n_embed, 4* n_embed),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*n_embed, n_embed),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ffw(x) # (B, context_size, n_embed) @ (n_embed, 4*n_embed) @ (4*n_embed, n_embed) --> (B, context_size, n_embed)\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, n_heads, n_embed, dropout):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(n_heads, n_embed, dropout)\n",
    "        self.ffw = FeedForward(n_embed, dropout)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x, mask = inputs\n",
    "        out = self.attention(x, x, mask)\n",
    "        out = self.ln1(out) + x\n",
    "        out = self.ffw(out)\n",
    "        out = self.ln2(out) + x\n",
    "        return (out, mask)\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, n_heads, n_embed, dropout):\n",
    "        super().__init__()\n",
    "        self.masked_attention = MultiHeadAttention(n_heads, n_embed, dropout)\n",
    "        self.attention = MultiHeadAttention(n_heads, n_embed, dropout)\n",
    "        self.ffw = FeedForward(n_embed, dropout)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "        self.ln3 = nn.LayerNorm(n_embed)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # unpack inputs\n",
    "        x, features, src_mask, targ_mask = inputs\n",
    "        out = self.masked_attention(x, x, targ_mask)\n",
    "        out = self.ln1(out) + x\n",
    "        out = self.attention(out, features, src_mask)\n",
    "        out = self.ln2(out) + x\n",
    "        out = self.ffw(out)\n",
    "        out = self.ln3(out) + x\n",
    "        return (out, features, src_mask, targ_mask)\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, n_embed, context_size):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        posem = torch.zeros((context_size+1, n_embed))\n",
    "        for pos in range(context_size+1):\n",
    "            for i in range(n_embed, 2):\n",
    "                posem[pos, i] = math.sin(pos/(10000**(2*i/n_embed)))\n",
    "                posem[pos, i+1] = math.cos(pos/(10000**(2*(i+1)/n_embed)))\n",
    "        posem.unsqueeze(0)\n",
    "        self.register_buffer(\"posem\", posem)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.posem[torch.arange(x.shape[1]),:]\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, n_embed, output_vocab_size):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(n_embed, output_vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.proj(x)\n",
    "\n",
    "class EncoderDecoderTransformer(nn.Module):\n",
    "    def __init__(self, n_heads, n_embed, dropout, n_blocks, context_size, input_vocab_size, output_vocab_size):\n",
    "        super().__init__()\n",
    "        self.input_embedding = nn.Embedding(input_vocab_size, n_embed)\n",
    "        self.positional_embedding = PositionalEmbedding(n_embed, context_size)\n",
    "        self.encoders = nn.Sequential(*[EncoderBlock(n_heads, n_embed, dropout) for _ in range(n_blocks)])\n",
    "        self.decoders = nn.Sequential(*[DecoderBlock(n_heads, n_embed, dropout) for _ in range(n_blocks)])\n",
    "        self.output = Generator(n_embed, output_vocab_size)\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        x = self.input_embedding(src)\n",
    "        x = self.positional_embedding(x)\n",
    "        x = self.encoders((x, src_mask))[0]\n",
    "        return x\n",
    "\n",
    "    def decode(self, targ, features, src_mask, targ_mask):\n",
    "        x = self.input_embedding(targ)\n",
    "        x = self.positional_embedding(x)\n",
    "        x = self.decoders((x , features, src_mask, targ_mask))[0]\n",
    "        return self.output(x)\n",
    "    \n",
    "    def forward(self, src, targ, src_mask, targ_mask):\n",
    "        x = self.encode(src, src_mask)\n",
    "        out = self.decode(targ, x, src_mask, targ_mask)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342d5ae9-f236-415d-bc64-f9ec8ef7ce0e",
   "metadata": {},
   "source": [
    "# very scratch test forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e409cb06-f994-47c8-8679-54fd7938f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: work out how to handle extracting k and v from multiple heads in final encoder block?? very possibly I should just rewrite in the kombo-head pattern \n",
    "\n",
    "model = EncoderDecoderTransformer(\n",
    "    n_heads=3, n_embed=6, dropout=0.2, n_blocks=5, context_size=12, input_vocab_size=12, output_vocab_size=12\n",
    ")\n",
    "\n",
    "# x = torch.arange(11)\n",
    "# y = torch.tensor([[0]])\n",
    "src = torch.tensor([[0, 2, 5, 6, 4, 3, 9, 5, 2, 9, 10, 1], \n",
    "                    [0, 2, 8, 7, 3, 4, 5, 6, 7, 2, 10, 1]])\n",
    "target = torch.tensor([[0, 1, 7, 4, 3, 5, 9, 2, 8, 10, 9, 1], \n",
    "                       [0, 1, 5, 6, 2, 4, 7, 6, 2, 8, 10, 1]])\n",
    "start_symbol = torch.zeros(target.shape[0], 1).fill_(11).type_as(target)\n",
    "y = torch.cat((start_symbol, target[:,:-1]), dim=1)\n",
    "src_mask, targ_mask = create_mask(src, target, 10)\n",
    "out = model(src, y, src_mask, targ_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "9df405d9-16af-4a4f-be26-48f76da33172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 12])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e06f27-8565-45d3-a903-533a2eae882c",
   "metadata": {},
   "source": [
    "# test on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "04299b62-079a-40be-a1de-45b613fcb62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_data(vocab_size, batch_size):\n",
    "    data = torch.randint(2, vocab_size+2, size=(batch_size, 10))\n",
    "    src = data.requires_grad_(False).clone().detach()\n",
    "    target = data.requires_grad_(False).clone().detach()\n",
    "    target = torch.cat((torch.zeros(target.shape[0], 1), target), dim=1)\n",
    "    target = torch.cat((target, torch.ones(target.shape[0], 1)), dim=1)\n",
    "    targ = target[:,:-1].type(torch.long)\n",
    "    labels = target[:,1:].type(torch.long)\n",
    "    src_mask, targ_mask = create_mask(src, targ, 99)\n",
    "    return [src, targ, labels, src_mask, targ_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6ed67acc-2208-4264-9775-a7185381a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "src, targ, labels, src_mask, targ_mask = generate_fake_data(10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ed269e6d-e15c-4fb5-927e-23cba42d188f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10]) tensor([ 9,  9,  6,  2, 10,  5,  6,  8,  3,  4])\n",
      "torch.Size([11]) tensor([ 0,  9,  9,  6,  2, 10,  5,  6,  8,  3,  4])\n",
      "torch.Size([11]) tensor([ 9,  9,  6,  2, 10,  5,  6,  8,  3,  4,  1])\n"
     ]
    }
   ],
   "source": [
    "print(src[0].shape, src[0])\n",
    "print(targ[0].shape, targ[0])\n",
    "print(labels[0].shape, labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4ec44491-5fe4-46b1-8e4a-38ce13237859",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create model\n",
    "model = EncoderDecoderTransformer(\n",
    "    n_heads=4, n_embed=64, dropout=0.2, n_blocks=6, context_size=20, input_vocab_size=12, output_vocab_size=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b9e234ce-5ece-4d8f-9be4-a80bc5986c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=0 loss.item()=3.368835687637329\n",
      "step=100 loss.item()=0.07858247309923172\n",
      "step=200 loss.item()=0.002147453837096691\n",
      "step=300 loss.item()=0.00025999455829150975\n",
      "step=400 loss.item()=0.0013830573298037052\n"
     ]
    }
   ],
   "source": [
    "## train model\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for step in range(500):\n",
    "    src, targ, labels, src_mask, targ_mask = generate_fake_data(10, 64)\n",
    "    # forward pass\n",
    "    logits = model(src, targ, src_mask, targ_mask)\n",
    "    loss = calculate_loss(logits, labels, 99)\n",
    "    losses.append(loss.item())\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if step % 100 == 0:\n",
    "        print(f\"{step=} {loss.item()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f7c29c13-4363-423e-9581-3183d5e9705e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11]) torch.Size([11, 12])\n",
      "tensor([ 2,  8,  6,  2, 11,  3,  9,  5,  7,  8,  1])\n",
      "tensor([ 2,  8,  6,  2, 11,  3,  9,  5,  7,  8,  1])\n",
      "tensor([ 2,  8,  6,  2, 11,  3,  9,  5,  7,  8])\n"
     ]
    }
   ],
   "source": [
    "print(labels[3].shape, logits[3].shape)\n",
    "print(labels[3])\n",
    "# print(logits[1])\n",
    "print(torch.argmax(logits[3], dim=1))\n",
    "# plt.imshow(model.decoders[0].masked_attention.attn_store[0,3].detach().numpy())\n",
    "print(src[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "062fcc33-b8a7-4a9f-b76d-0456e2666d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0cf7a4e190>]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3a7fae14-9c07-47d4-a93a-e2081683922f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  7, 10,  4, 11, 10,  9, 11, 10,  2]])\n",
      "tensor([ 2,  7, 10,  4, 11, 10,  9, 11, 10,  2], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "def greedy_decoding(model, src, context_size):\n",
    "    targ = torch.zeros(1,src.shape[1] + 1).type(torch.int)\n",
    "    src_mask, _ = create_mask(src, src, 99)\n",
    "    features = model.encode(src, src_mask)\n",
    "    for i in range(context_size):\n",
    "        src_mask, targ_mask = create_mask(src, targ, 99)\n",
    "        proj = model.decode(targ, features, src_mask, targ_mask)\n",
    "        tok = torch.argmax(proj[0,i,:], keepdims=True)\n",
    "        tok = tok.unsqueeze(0)\n",
    "        if tok.item() == 1:\n",
    "            return targ, proj\n",
    "        # cur_targ = torch.cat([cur_targ, tok], dim=1).type(torch.int)\n",
    "        targ[0, i+1] = tok\n",
    "    return targ, proj\n",
    "\n",
    "src = torch.randint(2, 12, size=(1, 10))\n",
    "\n",
    "targ, proj = greedy_decoding(model, src, 20)\n",
    "print(src)\n",
    "print(targ[0,1:])\n",
    "# print(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8f652514-6ce9-4295-90eb-6cb481d0c468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ans = torch.max(proj[0,0],0)\n",
    "# ans\n",
    "torch.zeros((1,1)).type(torch.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b9dad9-5f19-4f78-a1f5-eacb12f71d43",
   "metadata": {},
   "source": [
    "# test training on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df7dd8ed-52c5-46c1-b041-5d5aaa43d581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext.datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data = torchtext.datasets.Multi30k(split='train', language_pair=('de', 'en'))\n",
    "val_data = torchtext.datasets.Multi30k(split='valid', language_pair=('de', 'en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfda2e7e-4297-4106-9a72-6c729c9de94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "import de_core_news_sm\n",
    "\n",
    "en_tokenizer = en_core_web_sm.load()\n",
    "de_tokenizer = de_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf07167b-93bc-4a95-bd00-fcc368900741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/dev/translate-gpt/.env/lib/python3.11/site-packages/torch/utils/data/datapipes/iter/combining.py:333: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_unique_tokens(text, tokenizer):\n",
    "    cnt = Counter()\n",
    "    for doc in tokenizer.pipe(text):\n",
    "        doc_tokens = [tok.text.strip() for tok in doc if len(tok.text) > 0]\n",
    "        cnt.update(doc_tokens)\n",
    "    return [tok[0] for tok in cnt.most_common(10000)]\n",
    "\n",
    "src_text, targ_text = list(zip(*train_data))\n",
    "\n",
    "de_toks = get_unique_tokens(src_text, de_tokenizer)\n",
    "en_toks = get_unique_tokens(targ_text, en_tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50469226-4ede-4e94-b45a-1531f75cd8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# special token indices\n",
    "UNK_IDX = 0\n",
    "PAD_IDX = 1\n",
    "SOS_IDX = 2\n",
    "EOS_IDX = 3\n",
    "\n",
    "UNK = '<unk>' # Unknown\n",
    "PAD = '<pad>' # Padding\n",
    "SOS = '<sos>' # Start of sentence\n",
    "EOS = '<eos>' # End of sentence\n",
    "\n",
    "SPECIAL_TOKENS = [UNK, PAD, SOS, EOS]\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, tokenizer, tokens):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokens = SPECIAL_TOKENS + tokens\n",
    "        self.token_idxs = {self.tokens[i]: i for i in range(len(tokens))}\n",
    "\n",
    "    def __call__(self, text):\n",
    "        return [self.numerify(tok.text.strip()) for tok in self.tokenizer(text)]\n",
    "    \n",
    "    def numerify(self, tok):\n",
    "        if tok not in self.token_idxs:\n",
    "            return UNK_IDX\n",
    "        return self.token_idxs[tok]\n",
    "\n",
    "de_vocab = Vocab(de_tokenizer, de_toks)\n",
    "en_vocab = Vocab(en_tokenizer, en_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7d0d16d8-9663-4a70-9bb6-f11851499309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def make_dataloader(dataset, batch_size, context_size, device): \n",
    "    def collate_fn(batch):\n",
    "        srcs = []\n",
    "        targs = []\n",
    "        for i, (src_sentence, targ_sentence) in enumerate(batch):\n",
    "            src = de_vocab(src_sentence)\n",
    "            targ = [SOS_IDX] + en_vocab(targ_sentence) + [EOS_IDX]\n",
    "    \n",
    "            srcs.append(torch.tensor(src))\n",
    "            targs.append(torch.tensor(targ))\n",
    "    \n",
    "        src_batch = pad_sequence(srcs, padding_value=PAD_IDX, batch_first=True)\n",
    "        targ_batch = pad_sequence(targs, padding_value=PAD_IDX, batch_first=True)\n",
    "    \n",
    "        # decoder wants target starting with SOS\n",
    "        target_batch = targ_batch[:, :-1]\n",
    "        # however when calculating loss we are only interested in tokens after SOS and ending with EOS\n",
    "        label_batch = targ_batch[:, 1:]\n",
    "        src_mask, targ_mask = create_mask(src_batch, target_batch, PAD_IDX) # TODO: understand what the hell happens with different context lengths\n",
    "    \n",
    "        all_batches = [src_batch, target_batch, label_batch, src_mask, targ_mask]\n",
    "        return [b.to(device) for b in all_batches]\n",
    "\n",
    "    return DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "train_dataloader = make_dataloader(train_data, 32, 40, \"cpu\")\n",
    "val_dataloader = make_dataloader(val_data, 100, 40, \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "44d49ba4-0cdb-44e3-ab63-a4cd6de56d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1batch [00:00,  1.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=10.488906860351562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11batch [00:05,  1.90batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=5.766294956207275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21batch [00:10,  1.98batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=5.211877822875977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31batch [00:16,  1.98batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=5.110589027404785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41batch [00:21,  1.94batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=5.434295654296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51batch [00:26,  1.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=5.336674690246582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61batch [00:31,  1.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=5.0815253257751465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71batch [00:37,  1.83batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.955556392669678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81batch [00:42,  1.94batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.749855995178223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91batch [00:47,  1.91batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.6790032386779785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101batch [00:52,  1.95batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.954250812530518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "111batch [00:58,  1.96batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.744067192077637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121batch [01:03,  1.96batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.476064205169678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "131batch [01:08,  1.89batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.632311820983887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "141batch [01:13,  1.98batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.026826858520508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151batch [01:18,  1.99batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.9137227535247803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "161batch [01:23,  1.98batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=5.385863304138184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171batch [01:28,  1.95batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.399586200714111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "181batch [01:33,  1.96batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.283005714416504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "191batch [01:38,  2.00batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.398786544799805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201batch [01:43,  1.91batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.389658451080322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "211batch [01:49,  1.94batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.272395610809326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "221batch [01:54,  2.00batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.184638023376465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231batch [01:59,  1.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.027780055999756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "241batch [02:05,  1.60batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.8719496726989746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "251batch [02:11,  1.69batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.18194580078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "261batch [02:17,  1.65batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.22096586227417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "271batch [02:23,  1.71batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.9324278831481934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "281batch [02:29,  1.67batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.0414652824401855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "291batch [02:35,  1.63batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.929612159729004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301batch [02:41,  1.65batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.781160354614258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "311batch [02:47,  1.70batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.7743353843688965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "321batch [02:53,  1.68batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.184779644012451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "331batch [02:59,  1.66batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.86842679977417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "341batch [03:05,  1.64batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.4732236862182617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "351batch [03:11,  1.57batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.001214981079102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "361batch [03:17,  1.74batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.352128028869629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "371batch [03:23,  1.67batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.888756275177002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "381batch [03:29,  1.78batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.7395875453948975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391batch [03:35,  1.60batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.8262805938720703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401batch [03:41,  1.65batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.853325128555298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "411batch [03:47,  1.66batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.9283413887023926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "421batch [03:53,  1.63batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.604412794113159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "431batch [03:59,  1.69batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.3804831504821777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "441batch [04:05,  1.70batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.660642385482788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "451batch [04:11,  1.68batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.7757365703582764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "461batch [04:17,  1.66batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.71240496635437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "471batch [04:23,  1.73batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.9330320358276367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "481batch [04:29,  1.68batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.090284824371338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "491batch [04:35,  1.68batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.800464391708374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501batch [04:41,  1.62batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.087432384490967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "511batch [04:47,  1.63batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.7930638790130615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "521batch [04:54,  1.53batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.7781989574432373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "531batch [05:00,  1.64batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.721280813217163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "541batch [05:06,  1.43batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.839611291885376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "551batch [05:12,  1.82batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.796506881713867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "561batch [05:17,  1.85batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.588045597076416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "571batch [05:23,  1.93batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.5810084342956543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "581batch [05:28,  1.96batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.405695915222168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "591batch [05:33,  1.94batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.469553232192993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601batch [05:38,  1.90batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.5906829833984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "611batch [05:44,  1.85batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.8222100734710693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "621batch [05:49,  1.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.8393349647521973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "631batch [05:54,  1.86batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.7020654678344727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "641batch [06:00,  1.68batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.4514546394348145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "651batch [06:06,  1.61batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.570735454559326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "661batch [06:13,  1.59batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.546398878097534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "671batch [06:19,  1.56batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.4519433975219727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "681batch [06:25,  1.65batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.3525099754333496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "691batch [06:31,  1.50batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.8046820163726807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701batch [06:38,  1.63batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.207732677459717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "711batch [06:44,  1.64batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.8605751991271973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "721batch [06:50,  1.66batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.2472879886627197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "731batch [06:56,  1.64batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.635829448699951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "741batch [07:02,  1.58batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.8200509548187256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "751batch [07:08,  1.61batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.706303596496582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "761batch [07:15,  1.63batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.609208106994629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "771batch [07:21,  1.55batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.042797565460205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "781batch [07:27,  1.62batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.8586483001708984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "791batch [07:34,  1.58batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.8689069747924805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801batch [07:40,  1.53batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.729856014251709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "811batch [07:46,  1.62batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.9365382194519043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "821batch [07:53,  1.57batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.5630874633789062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "831batch [07:59,  1.64batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.761065721511841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "841batch [08:05,  1.55batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.026031017303467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "851batch [08:12,  1.54batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.7375261783599854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "861batch [08:18,  1.64batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.321027994155884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "871batch [08:24,  1.52batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=4.109722137451172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "881batch [08:31,  1.55batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.659573554992676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "891batch [08:37,  1.59batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.5265257358551025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901batch [08:43,  1.65batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.287187337875366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "907batch [08:47,  1.72batch/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = EncoderDecoderTransformer(\n",
    "    n_heads=8, n_embed=128, dropout=0.2, n_blocks=6, context_size=44, input_vocab_size=len(de_vocab.tokens), output_vocab_size=len(en_vocab.tokens)\n",
    ")\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "with tqdm(train_dataloader, unit=\"batch\") as iter:\n",
    "    losses = []\n",
    "    for step, (src, targ, labels, src_mask, targ_mask) in enumerate(iter):\n",
    "        # forward pass\n",
    "        logits = model(src, targ, src_mask, targ_mask)\n",
    "        loss = calculate_loss(logits, labels, PAD_IDX)\n",
    "        losses.append(loss.item())\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if step % 10 == 0:\n",
    "            print(f\"{loss.item()=}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "b889cffb-f120-41ab-ac28-e65d90d1eea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.210733413696289,\n",
       " 9.210726737976074,\n",
       " 9.21072769165039,\n",
       " 9.210715293884277,\n",
       " 9.210716247558594,\n",
       " 9.210707664489746,\n",
       " 9.210700035095215,\n",
       " 9.21069622039795,\n",
       " 9.210679054260254,\n",
       " 9.210673332214355,\n",
       " 9.210649490356445,\n",
       " 9.2106294631958,\n",
       " 9.210603713989258,\n",
       " 9.210601806640625,\n",
       " 9.210576057434082,\n",
       " 9.210556983947754,\n",
       " 9.210526466369629,\n",
       " 9.210470199584961,\n",
       " 9.21037769317627,\n",
       " 9.210357666015625,\n",
       " 9.210260391235352,\n",
       " 9.210247039794922,\n",
       " 9.210076332092285,\n",
       " 9.2099609375,\n",
       " 9.209695816040039,\n",
       " 9.209587097167969,\n",
       " 9.209501266479492,\n",
       " 9.20931625366211,\n",
       " 9.208842277526855,\n",
       " 9.208385467529297,\n",
       " 9.207955360412598,\n",
       " 9.207120895385742,\n",
       " 9.206398963928223,\n",
       " 9.205703735351562,\n",
       " 9.204448699951172,\n",
       " 9.20336627960205,\n",
       " 9.202404975891113,\n",
       " 9.199590682983398,\n",
       " 9.197884559631348,\n",
       " 9.194610595703125,\n",
       " 9.193553924560547,\n",
       " 9.187616348266602,\n",
       " 9.184483528137207,\n",
       " 9.179563522338867,\n",
       " 9.174766540527344,\n",
       " 9.166749954223633,\n",
       " 9.159613609313965,\n",
       " 9.157155990600586,\n",
       " 9.145181655883789,\n",
       " 9.141651153564453,\n",
       " 9.137707710266113,\n",
       " 9.125504493713379,\n",
       " 9.118682861328125,\n",
       " 9.115015983581543,\n",
       " 9.114116668701172,\n",
       " 9.107048988342285,\n",
       " 9.098224639892578,\n",
       " 9.094953536987305,\n",
       " 9.111604690551758,\n",
       " 9.09572696685791,\n",
       " 9.111954689025879,\n",
       " 9.0999116897583,\n",
       " 9.08913516998291,\n",
       " 9.096960067749023,\n",
       " 9.09214973449707,\n",
       " 9.094876289367676,\n",
       " 9.084139823913574,\n",
       " 9.098191261291504,\n",
       " 9.102437973022461,\n",
       " 9.096508026123047,\n",
       " 9.089198112487793,\n",
       " 9.102048873901367,\n",
       " 9.09325122833252,\n",
       " 9.092448234558105,\n",
       " 9.085984230041504,\n",
       " 9.076757431030273,\n",
       " 9.07886791229248,\n",
       " 9.084598541259766,\n",
       " 9.08089828491211,\n",
       " 9.076725006103516,\n",
       " 9.079070091247559,\n",
       " 9.060103416442871,\n",
       " 9.07491683959961,\n",
       " 9.080306053161621,\n",
       " 9.073908805847168,\n",
       " 9.071700096130371,\n",
       " 9.06954288482666,\n",
       " 9.071268081665039,\n",
       " 9.053308486938477,\n",
       " 9.068754196166992,\n",
       " 9.079970359802246,\n",
       " 9.066417694091797,\n",
       " 9.050100326538086,\n",
       " 9.058850288391113,\n",
       " 9.092436790466309,\n",
       " 9.086180686950684,\n",
       " 9.070035934448242,\n",
       " 9.082474708557129,\n",
       " 9.092291831970215,\n",
       " 9.051026344299316,\n",
       " 9.079747200012207,\n",
       " 9.052434921264648,\n",
       " 9.063150405883789,\n",
       " 9.064200401306152,\n",
       " 9.085500717163086,\n",
       " 9.062919616699219,\n",
       " 9.099628448486328,\n",
       " 9.07736873626709,\n",
       " 9.091144561767578,\n",
       " 9.047849655151367,\n",
       " 9.072866439819336,\n",
       " 9.055548667907715,\n",
       " 9.033740997314453,\n",
       " 9.033899307250977,\n",
       " 9.06374740600586,\n",
       " 9.0668306350708,\n",
       " 9.06919002532959,\n",
       " 9.048129081726074,\n",
       " 9.055610656738281,\n",
       " 9.042107582092285,\n",
       " 9.063436508178711,\n",
       " 9.07404613494873,\n",
       " 9.0599365234375,\n",
       " 9.057604789733887,\n",
       " 9.025341987609863,\n",
       " 9.090513229370117,\n",
       " 9.052477836608887,\n",
       " 9.043901443481445,\n",
       " 9.052360534667969,\n",
       " 9.071073532104492,\n",
       " 9.061756134033203,\n",
       " 9.042905807495117,\n",
       " 9.032676696777344,\n",
       " 9.040918350219727,\n",
       " 9.072782516479492,\n",
       " 9.063257217407227,\n",
       " 9.066011428833008,\n",
       " 9.048134803771973,\n",
       " 9.061553001403809,\n",
       " 9.018346786499023,\n",
       " 9.02640151977539,\n",
       " 9.039030075073242,\n",
       " 9.042122840881348,\n",
       " 9.054279327392578,\n",
       " 9.0629301071167,\n",
       " 9.049542427062988,\n",
       " 9.031105041503906,\n",
       " 9.049936294555664,\n",
       " 9.042040824890137,\n",
       " 9.047226905822754,\n",
       " 9.035606384277344,\n",
       " 9.049237251281738,\n",
       " 9.073176383972168,\n",
       " 9.040754318237305,\n",
       " 9.028788566589355,\n",
       " 9.056096076965332,\n",
       " 9.055209159851074,\n",
       " 9.047804832458496,\n",
       " 9.062042236328125,\n",
       " 9.061944961547852,\n",
       " 9.076016426086426,\n",
       " 9.055882453918457,\n",
       " 9.066293716430664,\n",
       " 9.046381950378418,\n",
       " 9.051111221313477,\n",
       " 9.044229507446289,\n",
       " 9.038456916809082,\n",
       " 9.044390678405762,\n",
       " 9.033525466918945,\n",
       " 9.05340576171875,\n",
       " 9.062559127807617,\n",
       " 9.043818473815918,\n",
       " 9.071027755737305,\n",
       " 9.038368225097656,\n",
       " 9.054885864257812,\n",
       " 9.057724952697754,\n",
       " 9.031654357910156,\n",
       " 9.042579650878906,\n",
       " 9.042238235473633,\n",
       " 9.057234764099121,\n",
       " 9.023770332336426,\n",
       " 9.023870468139648,\n",
       " 9.023515701293945,\n",
       " 9.050310134887695,\n",
       " 9.056798934936523,\n",
       " 9.047001838684082,\n",
       " 9.016963005065918,\n",
       " 9.016200065612793,\n",
       " 9.031546592712402,\n",
       " 9.056413650512695,\n",
       " 9.033185005187988,\n",
       " 9.062980651855469,\n",
       " 9.036255836486816,\n",
       " 9.008211135864258,\n",
       " 9.00996208190918,\n",
       " 9.028655052185059,\n",
       " 9.029109001159668,\n",
       " 9.02268123626709,\n",
       " 9.022317886352539,\n",
       " 9.036172866821289,\n",
       " 9.027458190917969,\n",
       " 9.023262977600098,\n",
       " 9.021990776062012,\n",
       " 9.051223754882812,\n",
       " 9.047110557556152,\n",
       " 9.012809753417969,\n",
       " 9.043220520019531,\n",
       " 9.028613090515137,\n",
       " 9.050232887268066,\n",
       " 9.063618659973145,\n",
       " 9.018912315368652,\n",
       " 9.045928955078125,\n",
       " 9.042427062988281,\n",
       " 9.03162956237793,\n",
       " 9.042215347290039,\n",
       " 9.044266700744629,\n",
       " 9.053359985351562,\n",
       " 9.013400077819824,\n",
       " 9.010404586791992,\n",
       " 9.008905410766602,\n",
       " 9.03642749786377,\n",
       " 9.013296127319336,\n",
       " 9.022054672241211,\n",
       " 9.04176139831543,\n",
       " 9.065828323364258,\n",
       " 9.040351867675781,\n",
       " 9.028120994567871,\n",
       " 9.017562866210938,\n",
       " 9.045670509338379,\n",
       " 9.040284156799316,\n",
       " 9.052026748657227,\n",
       " 9.016773223876953,\n",
       " 9.02374267578125,\n",
       " 9.03067684173584,\n",
       " 9.021974563598633,\n",
       " 9.034842491149902,\n",
       " 9.044097900390625,\n",
       " 9.025504112243652,\n",
       " 9.049234390258789,\n",
       " 9.011855125427246,\n",
       " 9.001538276672363,\n",
       " 9.038235664367676,\n",
       " 9.019204139709473,\n",
       " 9.033287048339844,\n",
       " 9.031943321228027,\n",
       " 9.039196968078613,\n",
       " 8.983844757080078,\n",
       " 9.038089752197266,\n",
       " 9.035642623901367,\n",
       " 9.035921096801758,\n",
       " 9.049471855163574,\n",
       " 9.037304878234863,\n",
       " 9.031453132629395,\n",
       " 9.03839111328125,\n",
       " 9.032052993774414,\n",
       " 9.033358573913574,\n",
       " 9.043278694152832,\n",
       " 9.038694381713867,\n",
       " 9.038849830627441,\n",
       " 9.026132583618164,\n",
       " 9.024253845214844,\n",
       " 8.99265193939209,\n",
       " 9.004500389099121,\n",
       " 9.002775192260742,\n",
       " 9.023649215698242,\n",
       " 9.03168773651123,\n",
       " 9.01458740234375,\n",
       " 9.02579402923584,\n",
       " 9.000861167907715,\n",
       " 9.00969409942627,\n",
       " 9.01122760772705,\n",
       " 9.040148735046387,\n",
       " 9.01521110534668,\n",
       " 8.998266220092773,\n",
       " 9.040159225463867,\n",
       " 9.02018928527832,\n",
       " 9.023670196533203,\n",
       " 9.012682914733887,\n",
       " 9.026900291442871,\n",
       " 9.002557754516602,\n",
       " 9.016337394714355,\n",
       " 9.025191307067871,\n",
       " 9.049012184143066,\n",
       " 9.005277633666992,\n",
       " 9.02589225769043,\n",
       " 9.019540786743164,\n",
       " 9.074464797973633,\n",
       " 9.012990951538086,\n",
       " 9.039250373840332,\n",
       " 9.033530235290527,\n",
       " 9.016438484191895,\n",
       " 9.01155948638916,\n",
       " 9.028852462768555,\n",
       " 8.99914264678955,\n",
       " 9.021931648254395,\n",
       " 9.02473258972168,\n",
       " 9.009943008422852,\n",
       " 9.030266761779785,\n",
       " 9.020366668701172,\n",
       " 9.02708625793457,\n",
       " 9.004523277282715,\n",
       " 9.019137382507324,\n",
       " 9.000540733337402,\n",
       " 9.014296531677246,\n",
       " 9.020438194274902,\n",
       " 9.017173767089844,\n",
       " 9.017481803894043,\n",
       " 9.029932975769043,\n",
       " 8.988335609436035,\n",
       " 9.008496284484863,\n",
       " 9.030062675476074,\n",
       " 9.01619815826416,\n",
       " 9.04478931427002,\n",
       " 9.003541946411133,\n",
       " 8.99193000793457,\n",
       " 9.011560440063477,\n",
       " 9.024621963500977,\n",
       " 9.002986907958984,\n",
       " 9.026864051818848,\n",
       " 9.022363662719727,\n",
       " 9.016047477722168,\n",
       " 9.011822700500488,\n",
       " 9.01626205444336,\n",
       " 9.01652717590332,\n",
       " 8.995285987854004,\n",
       " 8.99341106414795,\n",
       " 9.016355514526367,\n",
       " 9.005727767944336,\n",
       " 8.983531951904297,\n",
       " 9.007442474365234,\n",
       " 8.998820304870605,\n",
       " 9.024816513061523,\n",
       " 8.993029594421387,\n",
       " 9.028329849243164,\n",
       " 9.012158393859863,\n",
       " 8.98947525024414,\n",
       " 9.04966926574707,\n",
       " 9.000208854675293,\n",
       " 8.991866111755371,\n",
       " 9.03561019897461,\n",
       " 8.97903823852539,\n",
       " 8.994565963745117,\n",
       " 9.010847091674805,\n",
       " 9.004849433898926,\n",
       " 9.032432556152344,\n",
       " 9.018484115600586,\n",
       " 9.005134582519531,\n",
       " 9.030030250549316,\n",
       " 8.994182586669922,\n",
       " 8.994353294372559,\n",
       " 9.014290809631348,\n",
       " 8.984220504760742,\n",
       " 9.020604133605957,\n",
       " 9.030988693237305,\n",
       " 8.992573738098145,\n",
       " 8.986225128173828,\n",
       " 8.991613388061523,\n",
       " 8.95263385772705,\n",
       " 9.022767066955566,\n",
       " 8.97659969329834,\n",
       " 9.05443286895752,\n",
       " 9.003640174865723,\n",
       " 9.02672004699707,\n",
       " 9.027929306030273,\n",
       " 9.005536079406738,\n",
       " 8.99526309967041,\n",
       " 9.011590957641602,\n",
       " 8.979591369628906,\n",
       " 9.025153160095215,\n",
       " 9.026280403137207,\n",
       " 9.041675567626953,\n",
       " 8.98985767364502,\n",
       " 8.974828720092773,\n",
       " 9.007978439331055,\n",
       " 9.00865650177002,\n",
       " 8.974481582641602,\n",
       " 8.983123779296875,\n",
       " 9.007338523864746,\n",
       " 8.992838859558105,\n",
       " 8.99573802947998,\n",
       " 8.964580535888672,\n",
       " 8.976228713989258,\n",
       " 8.992645263671875,\n",
       " 9.006966590881348,\n",
       " 9.024894714355469,\n",
       " 9.006503105163574,\n",
       " 8.995659828186035,\n",
       " 8.983474731445312,\n",
       " 8.99973201751709,\n",
       " 9.024541854858398,\n",
       " 9.014985084533691,\n",
       " 8.998771667480469,\n",
       " 8.981289863586426,\n",
       " 9.001803398132324,\n",
       " 8.995285987854004,\n",
       " 8.978792190551758,\n",
       " 9.0062894821167,\n",
       " 8.995169639587402,\n",
       " 9.000661849975586,\n",
       " 9.007394790649414,\n",
       " 9.029491424560547,\n",
       " 9.015848159790039,\n",
       " 8.998018264770508,\n",
       " 8.992228507995605,\n",
       " 8.965563774108887,\n",
       " 8.987732887268066,\n",
       " 8.968405723571777,\n",
       " 9.00645923614502,\n",
       " 8.993032455444336,\n",
       " 8.978719711303711,\n",
       " 8.984395027160645,\n",
       " 8.987890243530273,\n",
       " 9.02092456817627,\n",
       " 9.041213035583496,\n",
       " 8.968016624450684,\n",
       " 8.998330116271973,\n",
       " 8.995320320129395,\n",
       " 8.996776580810547,\n",
       " 9.024230003356934,\n",
       " 9.009121894836426,\n",
       " 8.990285873413086,\n",
       " 8.969572067260742,\n",
       " 9.01685619354248,\n",
       " 8.979727745056152,\n",
       " 8.990325927734375,\n",
       " 9.004372596740723,\n",
       " 8.986501693725586,\n",
       " 8.989166259765625,\n",
       " 8.9663667678833,\n",
       " 9.013304710388184,\n",
       " 8.985082626342773,\n",
       " 9.00198745727539,\n",
       " 8.998734474182129,\n",
       " 8.989896774291992,\n",
       " 9.013388633728027,\n",
       " 9.008112907409668,\n",
       " 8.991601943969727,\n",
       " 8.989466667175293,\n",
       " 8.977238655090332,\n",
       " 9.000555038452148,\n",
       " 9.00655746459961,\n",
       " 8.977721214294434,\n",
       " 8.958983421325684,\n",
       " 8.980255126953125,\n",
       " 9.002497673034668,\n",
       " 8.973771095275879,\n",
       " 8.94599437713623,\n",
       " 9.002825736999512,\n",
       " 8.991846084594727,\n",
       " 8.9912748336792,\n",
       " 8.997050285339355,\n",
       " 8.992155075073242,\n",
       " 8.983184814453125,\n",
       " 8.955205917358398,\n",
       " 8.986879348754883,\n",
       " 8.98426342010498,\n",
       " 8.983352661132812,\n",
       " 8.983176231384277,\n",
       " 8.999954223632812,\n",
       " 9.033693313598633,\n",
       " 9.002702713012695,\n",
       " 9.006102561950684,\n",
       " 8.959248542785645,\n",
       " 8.98648452758789,\n",
       " 8.969547271728516,\n",
       " 8.985822677612305,\n",
       " 8.9480619430542,\n",
       " 8.97354507446289,\n",
       " 8.97057819366455,\n",
       " 9.00572681427002,\n",
       " 8.993941307067871,\n",
       " 8.9708890914917,\n",
       " 9.01473617553711,\n",
       " 8.981474876403809,\n",
       " 8.949609756469727,\n",
       " 8.989239692687988,\n",
       " 8.997932434082031,\n",
       " 8.995272636413574,\n",
       " 8.971061706542969,\n",
       " 9.02167797088623,\n",
       " 8.998924255371094,\n",
       " 8.989803314208984,\n",
       " 8.9755859375,\n",
       " 9.039819717407227,\n",
       " 9.005475044250488,\n",
       " 9.00915241241455,\n",
       " 8.98193645477295,\n",
       " 9.002971649169922,\n",
       " 8.96008586883545,\n",
       " 8.983412742614746,\n",
       " 8.963919639587402,\n",
       " 9.004706382751465,\n",
       " 8.971409797668457,\n",
       " 8.988368034362793,\n",
       " 8.98878002166748,\n",
       " 8.968408584594727,\n",
       " 8.955090522766113,\n",
       " 8.9707612991333,\n",
       " 9.000404357910156,\n",
       " 9.03887939453125,\n",
       " 8.98376750946045,\n",
       " 8.981912612915039,\n",
       " 9.000658988952637,\n",
       " 9.004633903503418,\n",
       " 8.968377113342285,\n",
       " 8.998983383178711,\n",
       " 8.976326942443848,\n",
       " 8.976366996765137,\n",
       " 9.001287460327148,\n",
       " 9.005531311035156,\n",
       " 8.99299430847168,\n",
       " 8.991203308105469,\n",
       " 8.985505104064941,\n",
       " 8.967951774597168,\n",
       " 8.971258163452148,\n",
       " 9.006478309631348,\n",
       " 8.984211921691895,\n",
       " 8.986452102661133,\n",
       " 8.993888854980469,\n",
       " 9.004196166992188,\n",
       " 8.994638442993164,\n",
       " 9.00056266784668,\n",
       " 8.988436698913574,\n",
       " 8.986042976379395,\n",
       " 8.987496376037598,\n",
       " 8.991812705993652,\n",
       " 8.95425033569336,\n",
       " 8.970975875854492,\n",
       " 8.957696914672852,\n",
       " 8.966001510620117,\n",
       " 8.972437858581543,\n",
       " 8.964829444885254,\n",
       " 8.957490921020508,\n",
       " 8.998080253601074,\n",
       " 8.966541290283203,\n",
       " 8.971887588500977,\n",
       " 8.9728364944458,\n",
       " 8.991049766540527,\n",
       " 9.002668380737305,\n",
       " 8.977991104125977,\n",
       " 8.976280212402344,\n",
       " 8.982826232910156,\n",
       " 8.980067253112793,\n",
       " 9.005341529846191,\n",
       " 9.005057334899902,\n",
       " 8.9745512008667,\n",
       " 8.971820831298828,\n",
       " 8.97265625,\n",
       " 8.963216781616211,\n",
       " 8.994813919067383,\n",
       " 9.011720657348633,\n",
       " 8.981667518615723,\n",
       " 8.969255447387695,\n",
       " 8.953774452209473,\n",
       " 8.972554206848145,\n",
       " 8.9873046875,\n",
       " 8.978610038757324,\n",
       " 8.96315860748291,\n",
       " 9.004314422607422,\n",
       " 8.9480562210083,\n",
       " 8.958436012268066,\n",
       " 8.987419128417969,\n",
       " 8.981958389282227,\n",
       " 8.962508201599121,\n",
       " 8.974649429321289,\n",
       " 8.983742713928223,\n",
       " 8.949958801269531,\n",
       " 8.995916366577148,\n",
       " 8.961541175842285,\n",
       " 8.990371704101562,\n",
       " 8.952786445617676,\n",
       " 8.930487632751465,\n",
       " 8.943865776062012,\n",
       " 8.964240074157715,\n",
       " 8.97286605834961,\n",
       " 8.993611335754395,\n",
       " 8.927567481994629,\n",
       " 8.922533988952637,\n",
       " 8.997506141662598,\n",
       " 8.976211547851562,\n",
       " 8.907593727111816,\n",
       " 8.967700004577637,\n",
       " 9.015283584594727,\n",
       " 8.973776817321777,\n",
       " 8.972067832946777,\n",
       " 8.962993621826172,\n",
       " 8.970808029174805,\n",
       " 8.946940422058105,\n",
       " 8.987009048461914,\n",
       " 8.99454116821289,\n",
       " 8.946897506713867,\n",
       " 8.979299545288086,\n",
       " 9.006949424743652,\n",
       " 8.953326225280762,\n",
       " 8.94338321685791,\n",
       " 8.95864200592041,\n",
       " 8.970560073852539,\n",
       " 8.96462631225586,\n",
       " 8.92392635345459,\n",
       " 8.96469497680664,\n",
       " 9.004509925842285,\n",
       " 8.961433410644531,\n",
       " 8.995901107788086,\n",
       " 8.990301132202148,\n",
       " 8.996987342834473,\n",
       " 8.991990089416504,\n",
       " 8.954258918762207,\n",
       " 8.93386459350586,\n",
       " 8.956686973571777,\n",
       " 8.955207824707031,\n",
       " 8.9861421585083,\n",
       " 8.96372127532959,\n",
       " 8.995182991027832,\n",
       " 8.99239730834961,\n",
       " 8.966235160827637,\n",
       " 8.92917537689209,\n",
       " 8.96825122833252,\n",
       " 8.944616317749023,\n",
       " 8.937743186950684,\n",
       " 8.982080459594727,\n",
       " 8.995495796203613,\n",
       " 8.964574813842773,\n",
       " 8.942163467407227,\n",
       " 8.94806957244873,\n",
       " 8.95417594909668,\n",
       " 8.934605598449707,\n",
       " 8.975604057312012,\n",
       " 8.979962348937988,\n",
       " 8.93744945526123,\n",
       " 8.983716011047363,\n",
       " 8.96332836151123,\n",
       " 8.951961517333984,\n",
       " 8.967535972595215,\n",
       " 8.977333068847656,\n",
       " 8.944449424743652,\n",
       " 8.96138858795166,\n",
       " 8.959214210510254,\n",
       " 8.947473526000977,\n",
       " 9.008980751037598,\n",
       " 8.950282096862793,\n",
       " 8.950708389282227,\n",
       " 8.948174476623535,\n",
       " 8.954864501953125,\n",
       " 8.96466064453125,\n",
       " 8.975053787231445,\n",
       " 8.934107780456543,\n",
       " 8.943486213684082,\n",
       " 8.957798957824707,\n",
       " 8.973814964294434,\n",
       " 8.92164421081543,\n",
       " 8.98873519897461,\n",
       " 8.970793724060059,\n",
       " 8.9834566116333,\n",
       " 9.000216484069824,\n",
       " 8.975708961486816,\n",
       " 8.985182762145996,\n",
       " 8.985700607299805,\n",
       " 8.952420234680176,\n",
       " 8.93856143951416,\n",
       " 8.954245567321777,\n",
       " 8.970311164855957,\n",
       " 8.942707061767578,\n",
       " 8.963884353637695,\n",
       " 8.944463729858398,\n",
       " 8.958147048950195,\n",
       " 8.950353622436523,\n",
       " 8.98619556427002,\n",
       " 8.9861421585083,\n",
       " 8.929962158203125,\n",
       " 8.947572708129883,\n",
       " 8.959149360656738,\n",
       " 8.972265243530273,\n",
       " 8.964701652526855,\n",
       " 8.933820724487305,\n",
       " 8.967314720153809,\n",
       " 8.972844123840332,\n",
       " 8.963569641113281,\n",
       " 8.928304672241211,\n",
       " 8.940223693847656,\n",
       " 8.95785140991211,\n",
       " 8.920761108398438,\n",
       " 8.959795951843262,\n",
       " 8.926478385925293,\n",
       " 8.951774597167969,\n",
       " 8.94590950012207,\n",
       " 8.975558280944824,\n",
       " 8.954142570495605,\n",
       " 8.950888633728027,\n",
       " 8.956591606140137,\n",
       " 8.947998046875,\n",
       " 8.965910911560059,\n",
       " 8.963939666748047,\n",
       " 8.93604564666748,\n",
       " 8.973974227905273,\n",
       " 8.978303909301758,\n",
       " 8.976014137268066,\n",
       " 8.980868339538574,\n",
       " 8.937904357910156,\n",
       " 8.943306922912598,\n",
       " 8.962831497192383,\n",
       " 8.92894172668457,\n",
       " 8.939665794372559,\n",
       " 8.952801704406738,\n",
       " 8.942291259765625,\n",
       " 8.9008150100708,\n",
       " 8.960722923278809,\n",
       " 8.956812858581543,\n",
       " 8.943089485168457,\n",
       " 8.94989013671875,\n",
       " 8.936909675598145,\n",
       " 8.949209213256836,\n",
       " 8.957842826843262,\n",
       " 8.94411849975586,\n",
       " 8.96369743347168,\n",
       " 8.937987327575684,\n",
       " 8.95354175567627,\n",
       " 8.938924789428711,\n",
       " 8.9351806640625,\n",
       " 8.950597763061523,\n",
       " 8.943975448608398,\n",
       " 8.953653335571289,\n",
       " 8.92259693145752,\n",
       " 8.969404220581055,\n",
       " 8.960054397583008,\n",
       " 8.959206581115723,\n",
       " 8.943023681640625,\n",
       " 8.947346687316895,\n",
       " 8.94072437286377,\n",
       " 8.952583312988281,\n",
       " 8.97819995880127,\n",
       " 8.944999694824219,\n",
       " 8.959436416625977,\n",
       " 8.941776275634766,\n",
       " 8.927050590515137,\n",
       " 8.945035934448242,\n",
       " 8.940093040466309,\n",
       " 8.973464012145996,\n",
       " 8.960786819458008,\n",
       " 8.999029159545898,\n",
       " 8.933244705200195,\n",
       " 8.95530891418457,\n",
       " 8.981528282165527,\n",
       " 9.004400253295898,\n",
       " 8.950428009033203,\n",
       " 8.989931106567383,\n",
       " 8.935125350952148,\n",
       " 8.944375991821289,\n",
       " 8.961345672607422,\n",
       " 8.943779945373535,\n",
       " 8.956189155578613,\n",
       " 8.918329238891602,\n",
       " 8.957637786865234,\n",
       " 8.965670585632324,\n",
       " 8.953780174255371,\n",
       " 8.972250938415527,\n",
       " 8.971830368041992,\n",
       " 8.971497535705566,\n",
       " 8.940346717834473,\n",
       " 8.945210456848145,\n",
       " 8.954736709594727,\n",
       " 8.962823867797852,\n",
       " 8.973306655883789,\n",
       " 8.984845161437988,\n",
       " 8.977458953857422,\n",
       " 8.944430351257324,\n",
       " 8.952973365783691,\n",
       " 8.992877006530762,\n",
       " 8.975528717041016,\n",
       " 8.985025405883789,\n",
       " 8.949719429016113,\n",
       " 8.9678373336792,\n",
       " 8.980511665344238,\n",
       " 8.958382606506348,\n",
       " 8.95005989074707,\n",
       " 8.958703994750977,\n",
       " 8.944197654724121,\n",
       " 8.969404220581055,\n",
       " 8.964425086975098,\n",
       " 8.962494850158691,\n",
       " 8.949481964111328,\n",
       " 8.957608222961426,\n",
       " 8.977035522460938,\n",
       " 8.982318878173828,\n",
       " 8.983074188232422,\n",
       " 8.96745491027832,\n",
       " 8.960586547851562,\n",
       " 8.977639198303223,\n",
       " 8.952213287353516,\n",
       " 8.935676574707031,\n",
       " 8.97181224822998,\n",
       " 8.950309753417969,\n",
       " 8.988412857055664,\n",
       " 8.97470474243164,\n",
       " 8.956396102905273,\n",
       " 8.97292709350586,\n",
       " 8.97603702545166,\n",
       " 8.974235534667969,\n",
       " 8.966174125671387,\n",
       " 8.976862907409668,\n",
       " 8.933876037597656,\n",
       " 8.952887535095215,\n",
       " 9.01418685913086,\n",
       " 8.946417808532715,\n",
       " 8.950118064880371,\n",
       " 8.998867988586426,\n",
       " 8.9913911819458,\n",
       " 8.95733642578125,\n",
       " 8.946128845214844,\n",
       " 8.980673789978027,\n",
       " 8.943230628967285,\n",
       " 8.971698760986328,\n",
       " 8.952363014221191,\n",
       " 9.000535011291504,\n",
       " 8.99055290222168,\n",
       " 8.984518051147461,\n",
       " 8.972675323486328,\n",
       " 8.946248054504395,\n",
       " 8.957158088684082,\n",
       " 8.956257820129395,\n",
       " 8.96877384185791,\n",
       " 8.983675956726074,\n",
       " 8.985193252563477,\n",
       " 8.943940162658691,\n",
       " 8.985467910766602,\n",
       " 8.975461959838867,\n",
       " 8.969107627868652,\n",
       " 8.937906265258789,\n",
       " 8.982027053833008,\n",
       " 8.98660945892334,\n",
       " 8.989219665527344,\n",
       " 8.962743759155273,\n",
       " 8.960007667541504,\n",
       " 8.945086479187012,\n",
       " 8.967142105102539,\n",
       " 8.971939086914062,\n",
       " 8.98206901550293,\n",
       " 8.99300765991211,\n",
       " 8.968809127807617,\n",
       " 8.987422943115234,\n",
       " 8.989272117614746,\n",
       " 8.969167709350586,\n",
       " 8.945205688476562,\n",
       " 8.962418556213379,\n",
       " 8.97531509399414,\n",
       " 8.96672248840332,\n",
       " 9.002305030822754,\n",
       " 8.992376327514648,\n",
       " 8.984955787658691,\n",
       " 8.988970756530762,\n",
       " 8.951641082763672,\n",
       " 8.966465950012207,\n",
       " 8.9686861038208,\n",
       " 8.992164611816406,\n",
       " 8.995080947875977,\n",
       " 8.961695671081543,\n",
       " 8.965744972229004,\n",
       " 8.959922790527344,\n",
       " 8.944656372070312,\n",
       " 8.961111068725586,\n",
       " 8.983402252197266,\n",
       " 8.944661140441895,\n",
       " 8.945082664489746,\n",
       " 8.942806243896484,\n",
       " 8.988676071166992,\n",
       " 8.960403442382812,\n",
       " 8.974374771118164,\n",
       " 8.941678047180176,\n",
       " 8.920089721679688,\n",
       " 8.991167068481445,\n",
       " 8.962867736816406,\n",
       " 9.003609657287598,\n",
       " 9.005640029907227,\n",
       " 8.965331077575684,\n",
       " 8.972938537597656,\n",
       " 8.968342781066895,\n",
       " 8.9480619430542,\n",
       " 8.981779098510742,\n",
       " 9.003059387207031,\n",
       " 8.9691162109375,\n",
       " 8.959053993225098,\n",
       " 8.96571159362793,\n",
       " 9.003913879394531,\n",
       " 8.990076065063477,\n",
       " 9.013189315795898,\n",
       " 9.002450942993164,\n",
       " 8.94021987915039,\n",
       " 8.929539680480957,\n",
       " 8.976577758789062,\n",
       " 8.954513549804688,\n",
       " 8.95176887512207,\n",
       " 8.964508056640625,\n",
       " 8.955805778503418,\n",
       " 8.924777030944824,\n",
       " 8.938102722167969,\n",
       " 8.953462600708008,\n",
       " 8.977640151977539,\n",
       " 8.970452308654785,\n",
       " 8.936053276062012,\n",
       " 8.93466854095459,\n",
       " 8.939976692199707,\n",
       " 8.915078163146973,\n",
       " 8.928078651428223,\n",
       " 8.94130802154541,\n",
       " 8.954496383666992,\n",
       " 8.944884300231934,\n",
       " 8.90363883972168,\n",
       " 8.924519538879395]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91e849c3-2a13-4eaa-9934-c685b1424075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0cfc218050>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687bcde7-4cd3-4b08-bd81-60a9ae6cb24b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
